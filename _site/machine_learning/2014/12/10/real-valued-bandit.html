<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Real Valued Multi-Armed Bandits</title>
    <meta name="description" content="Keenon Werling rants about things, and leaves it on the Internet
">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="http://keenon.github.io/machine_learning/2014/12/10/real-valued-bandit.html">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">There must be a better way</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Real Valued Multi-Armed Bandits</h1>
    <p class="post-meta">Dec 10, 2014</p>
    <script type="text/javascript"
  		src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
  </header>

  <article class="post-content">
    <p>Optimizing a modern digital product is complicated, labor intensive, and riddled with traps. The current state of the industry (though by no means state-of-the-art) is to use A/B testing to optimize websites. This involves getting a designer to make several different versions of something you’d like to optimize (say, a landing page), and then presenting each option to a randomly selected subset of the traffic to your site. By measuring visitors’ behavior on each of the versions, you can pick the one that maximizes profit for your business. The leader in the space has <a href="https://www.optimizely.com/ab-testing/">a great explanation of A/B testing</a>, if you want more detail.</p>

<p>The trouble is, A/B testing is hopelessly limited. You have to specify all your experiments in advance, and your only degree of freedom to optimize against is which version you choose. In mathematical terms, my gripe with A/B testing is that it’s over <em>discrete space</em>. For something like a videogame, where there’s lots of <em>continuous space</em> (how high should you be able to jump, how much health should you have, etc), you need a more sophisticated method for optimization.</p>

<p>That’s what we’ve created.</p>

<p>In probability, there’s a concept of <a href="http://en.wikipedia.org/wiki/Expected_value">expected value</a>, which is</p>

<p><img src="/assets/bandit/figure_2.png" alt="Golden user preferences" /></p>

<p><img src="/assets/bandit/figure_3.png" alt="Learned user preferences" /></p>

<p>We choose to model the transition probabilities from a node to a given child by the output of an SVM, normalized across the multiple possible outputs.</p>

<script type="math/tex; mode=display">
f(x) \propto \sum_{i = 1}^m a_iy_iK(x_i,x) + b
</script>

<p>We have a set of <script type="math/tex">n</script> children, where child <script type="math/tex">i</script> has expected value <script type="math/tex">E_i</script>. We are interested in our expected value, given a choice of <script type="math/tex">x</script>, representing the feature vector for creating a website.</p>

<script type="math/tex; mode=display">
E(x) = \frac{\sum_{i=1}^nE_i(\sum_{j=1}^m a_j^{(i)}y_j^{(i)}K(x_j^{(i)},x) + b_i)}{\sum_{i=1}^n\sum_{j=1}^m a_j^{(i)}y_j^{(i)}K(x_j^{(i)},x) + b_i}
</script>

<p>We wish to choose an <script type="math/tex">x</script> that maximizes our expected value under the model, given our evidence so far. This is non-convex, so we’d like a solution in closed form. Begin by taking the derivative</p>

<script type="math/tex; mode=display">
\frac{d}{dx}E(x) = \frac{d}{dx}\frac{\sum_{i=1}^nE_i(\sum_{j=1}^m a_j^{(i)}y_j^{(i)}K(x_j^{(i)},x) + b_i)}{\sum_{i=1}^n\sum_{j=1}^m a_j^{(i)}y_j^{(i)}K(x_j^{(i)},x) + b_i}
</script>

<p>In order to fit the entire derivative on one line, let:</p>

<script type="math/tex; mode=display">
d(x) = \sum_{i=1}^n\sum_{j=1}^m a_j^{(i)}y_j^{(i)}K(x_j^{(i)},x)
</script>

<script type="math/tex; mode=display">
e(x) = \sum_{i=1}^nE_i(\sum_{j=1}^m a_j^{(i)}y_j^{(i)}K(x_j^{(i)},x))
</script>

<p>Then by the quotient rule, we have</p>

<script type="math/tex; mode=display">
\frac{d}{dx}E(x) = \frac{d(x)\frac{d}{dx}e(x) - e(x)\frac{d}{dx}d(x)}{(d(x))^2}
</script>

<p>Following convention, let’s choose the Guassian kernel as our kernel:</p>

<script type="math/tex; mode=display">
K(y,x) = e^{-\frac{||x-y||^2}{2\sigma^2}}
</script>

<p>We’ll need the derivative also. We use the fact: <script type="math/tex">
||x-y||^2 = ||x||^2 - 2x^Ty + ||y||^2
</script></p>

<script type="math/tex; mode=display">
\frac{d}{dx} K(y,x) = \frac{d}{dx} e^{-\frac{||x||^2 - 2x^Ty + ||y||^2}{2\sigma^2}}
</script>

<p>Then we apply the chain rule and arrive at</p>

<script type="math/tex; mode=display">
\frac{d}{dx} K(y,x) = (e^{-\frac{||x||^2 - 2x^Ty + ||y||^2}{2\sigma^2}})*(\frac{y - x}{\sigma^2})
</script>

<p>And simplifying:</p>

<script type="math/tex; mode=display">
\frac{d}{dx} K(y,x) = e^{-\frac{||x-y||^2}{2\sigma^2}}(\frac{y - x}{\sigma^2})
</script>

<p>Then we can substitute in and get our final derivative (written in pieces so it fits onto a sheet of paper):</p>

<script type="math/tex; mode=display">
d(x) = \sum_{i=1}^n\sum_{j=1}^m a_j^{(i)}y_j^{(i)}e^{-\frac{||x-x_j^{(i)}||^2}{2\sigma^2}}
</script>

<script type="math/tex; mode=display">
\frac{d}{dx}d(x) = \sum_{i=1}^n\sum_{j=1}^m a_j^{(i)}y_j^{(i)}e^{-\frac{||x-x_j^{(i)}||^2}{2\sigma^2}}(\frac{x_j^{(i)} - x}{\sigma^2})
</script>

<script type="math/tex; mode=display">
e(x) = \sum_{i=1}^nE_i(\sum_{j=1}^m a_j^{(i)}y_j^{(i)}e^{-\frac{||x-x_j^{(i)}||^2}{2\sigma^2}})
</script>

<script type="math/tex; mode=display">
\frac{d}{dx}e(x) = \sum_{i=1}^nE_i(\sum_{j=1}^m a_j^{(i)}y_j^{(i)}e^{-\frac{||x-x_j^{(i)}||^2}{2\sigma^2}}(\frac{x_j^{(i)} - x}{\sigma^2}))
</script>

<script type="math/tex; mode=display">
\frac{d}{dx}E(x) = \frac{d(x)\frac{d}{dx}e(x) - e(x)\frac{d}{dx}d(x)}{(d(x))^2}
</script>

<p>Our expectation in <script type="math/tex">x</script> is non-concave and has many local optima. In practice, we use gradient descent with several restarts per problem to find the best value we can, with no optimality guarantees. Below is a graph of a gradient check on a toy dataset, with 6 potential user actions, each with a different expected value, resulting in 2 distinct (identical) peaks.</p>

<p><img src="/assets/bandit/figure_1.png" alt="Gradient check for multi-armed bandit" /></p>

<p>Cheers,
Keenon</p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">There must be a better way</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>There must be a better way</li>
          <li><a href="mailto:keenon@stanford.edu">keenon@stanford.edu</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/keenon">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">keenon</span>
            </a>
          </li>
          

          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">Keenon Werling rants about things, and leaves it on the Internet
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
